{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apprentice Challenge\n",
    "\n",
    "This challenge is diagnostic of your current python pandas, matplotlib/seaborn, and numpy skills. These diagnostics will help inform your selection into the Machine Learning Guild's Apprentice program. Please ensure you are using Python 3 as the notebook won't work in 2.7\n",
    "\n",
    "## Challenge Background: AirBnB Price Prediction\n",
    "\n",
    "\n",
    "\n",
    "![SegmentLocal](airbnbland.gif \"https://media.giphy.com/media/jdEMZDHtKNBpFAv1ud/giphy-downsized-large.gif\")\n",
    "\n",
    "AirBnB is a popular technology platform that serves as an online marketplace for lodging. Using AirBnB, homeowners (called \"hosts\") can  rent out their properties to travelers. Some hosts rent out their properties in full (e.g. an entire house or apartment), whereas some rent out individual rooms separately. Units are rented out for various durations, anywhere from one night up to a month or more, with some hosts specifying a minimum number of nights required for a rental.\n",
    "\n",
    "Over time, this platform has proven to be a powerful competitor to the traditional hotel and bed & breakfast industries, often competing on price, convenience, comfort, and/or the unique nature of its listed properties. \n",
    "\n",
    "The company is constantly onboarding new rental hosts in NYC, and many of these hosts don’t have any idea how much customers would be willing to pay for their rental units. AirBnB has hired you, an analytics consultant, to use their historical NYC rental data and build a predictive model that their new hosts in the city can use to get a sense of what to charge.\n",
    "\n",
    "In this data analysis programming challenge, you’ll have to clean the data, engineer some new modeling features, and finally, build and test the predictive model.\n",
    "\n",
    "\n",
    "## Instructions\n",
    "\n",
    "You need to know your way around `pandas` DataFrames and basic Python programming. You have **2 hours** to complete the challenge. We strongly discourage searching the internet for challenge answers.\n",
    "\n",
    "Your first task:\n",
    "* Read the first paragraph above to familiarize yourself with the topic.\n",
    "* Feel free to poke around with the iPython notebook.\n",
    "* When you are ready, proceed to the next task.\n",
    "* Complete each of the tasks listed below in the notebook.\n",
    "* You need to provide your code for challenge in the cells which say \"-- YOUR CODE FOR TASK NUMBER --\"\n",
    "\n",
    "**NOTE: After each Jupyter cell in which you will enter your code, there is an additional cell that will check your outputs. If your outputs are incorrect, this will be printed out for your awareness, and the correct outputs will be loaded in so that you can continue with the assessment. That being said, if you feel you are able to correct your code so that it generates the correct outputs, you should do so in order to get as many points as possible.**\n",
    "\n",
    "**Please reach out to [Lauren Moy](mailto:lmoy@deloitte.com) with any questions.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import data_load_files\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import mean_squared_error,r2_score, mean_absolute_error\n",
    "from sklearn import preprocessing\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1\n",
    "\n",
    "**Instructions**\n",
    "\n",
    "AirBnB just sent you the NYC rentals data as a text file (`AB_NYC_2019_pt1.csv`). First, we'll need to read that text file in as a pandas DataFrame called `df`. As it turns out, AirBnB also received an additional update (`AB_NYC_2019_pt2.csv`) overnight to add to the main dataset, so you'll have to read that in and append it to the main DataFrame as well.\n",
    "\n",
    "Next, to better understand the data, print the first 10 rows of the DataFrame, then print the data types of the DataFrame's columns\n",
    "\n",
    "\n",
    "**Expected Output**\n",
    "* (1pt) Read in the main data file as `df`, a pandas DataFrame and load in the second data file as `df2`\n",
    "* (1pt) Append the new data file to `df`\n",
    "* (1pt) Print the first 10 rows of the df and the datatypes of the df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Task 1\n",
    "\n",
    "# -- YOUR CODE FOR TASK 1 --\n",
    "\n",
    "#Import primary AirBnB data file as a pandas DataFrame\n",
    "df = ...\n",
    "\n",
    "\n",
    "\n",
    "#Import the additional AirBnB data file as a pandas DataFrame and append it to the primary data DataFrame\n",
    "df2 = ...\n",
    "\n",
    "\n",
    "#Append df2 to df\n",
    "df = ...\n",
    "\n",
    "\n",
    "#Print the first 10 rows of the df, and print the data types of the df's columns\n",
    "# Your code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## RUN THIS CELL AS-IS TO CHECK IF YOUR OUTPUTS ARE CORRECT. IF THEY ARE NOT,\n",
    "## THE APPROPRIATE OBJECTS WILL BE LOADED IN TO ENSURE THAT YOU CAN CONTINUE\n",
    "## WITH THE ASSESSMENT.\n",
    "\n",
    "task_1_check = data_load_files.TASK_1_OUTPUT\n",
    "task_1_shape = task_1_check.shape\n",
    "task_1_columns = task_1_check.columns\n",
    "\n",
    "if df.shape == task_1_shape and list(df.columns) == list(task_1_columns):\n",
    "    print('df is correct')\n",
    "else:    \n",
    "    df = task_1_check\n",
    "    print(\"'`df' is incorrect. You can correct for points, but you will still be able to move on to the next task if not.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2, Part 1\n",
    "**Instructions**\n",
    "\n",
    "AirBnB is aware that some of its listings are missing values. Let's see if we can determine how much of the dataset is affected. Start by printing out the number of rows in the df that contain any null (NaN) values.\n",
    "\n",
    "Once you've done that, drop those rows from the df before any further analysis is conducted.\n",
    "\n",
    "One of your fellow analytics consultants who was also exploring this data has been having trouble with their analysis. It seems to be due to a data type mismatch. In particular, they need the `last_review` column to be of type Datetime. Convert that column to Datetime for your teammate.\n",
    "\n",
    "\n",
    "**Expected Output**\n",
    "\n",
    "- (1pt) Correct number of rows that conain any null (NaN) values stored in a variable `num_nan`\n",
    "- (1pt) Updated DataFrame `df` where all rows that contain any NaNs have been dropped\n",
    "- (1pt) Updated DataFrame `df` where the dtype of column `last_review` is `datetime`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 2 (Part 1)\n",
    "\n",
    "# Import packages\n",
    "import datetime\n",
    "\n",
    "\n",
    "# -- YOUR CODE FOR TASK 2 (PART 1) --\n",
    "\n",
    "#Print out the number of rows in the df that contain any null (NaN) values\n",
    "num_nan = ...\n",
    "print(num_nan)\n",
    "\n",
    "#Drop all rows with any NaNs from the DataFrame\n",
    "# Your code here\n",
    "\n",
    "\n",
    "#Convert the ‘last_review’ column to DateTime\n",
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## RUN THIS CELL AS-IS TO CHECK IF YOUR OUTPUTS ARE CORRECT. IF THEY ARE NOT,\n",
    "## THE APPROPRIATE OBJECTS WILL BE LOADED IN TO ENSURE THAT YOU CAN CONTINUE\n",
    "## WITH THE ASSESSMENT.\n",
    "\n",
    "## Checks\n",
    "task_2_part_1_check = data_load_files.TASK_2_PART_1_OUTPUT\n",
    "\n",
    "shape_check = (df.shape == task_2_part_1_check.shape)\n",
    "columns_check = (list(df.columns) == list(task_2_part_1_check.columns))\n",
    "type_check = (type(df['last_review']) == type(task_2_part_1_check['last_review']))\n",
    "\n",
    "if shape_check and columns_check and type_check:\n",
    "    print('df is correct')\n",
    "else:    \n",
    "    df = task_2_part_1_check\n",
    "    print(\"'`df' is incorrect. You can correct for points, but you will still be able to move on to the next task if not.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2, Part 2\n",
    "\n",
    "**Instructions**\n",
    "\n",
    "Airbnb team wants to further explore the expansion of their listings in the Neighbourhood Group of Brooklyn. Create a DataFrame `df_brooklyn` containing only these listings, and then, using that DataFrame, create a new DataFrame `df_brooklyn_prices_room_type` showing the mean price per room type, which will help them determine the room types that generate the highest revenue.\n",
    "\n",
    "AirBnB also wants to understand which neighbourhoods in the Brooklyn neighbourhood group are most common among its listings. Create a pandas Series `top_10_brooklyn_series` that contains the top 10 most common neighborhoods (as the index) in Brooklyn and the number of listings each represents.\n",
    "\n",
    "**Expected Output**\n",
    "- (1pt) A DataFrame `df_brooklyn` that only contains listings in Brooklyn. Don't forget to reset the index if needed\n",
    "- (1pt) Create a dataframe `df_brooklyn_prices_room_type` showing the average (mean) prices of the listings for each room type in Brooklyn. This new DataFrame should contain only three columns: `neighbourhood_group`,`room_type`, and `price`. Don't forget to reset the index, if needed.\n",
    "- (1pt) A Series `top_10_brooklyn_series` that contains the number of listings for only the top 10 most common neighborhoods in Brooklyn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell \n",
    "pd.set_option('mode.chained_assignment', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 2 (Part 2)\n",
    "\n",
    "# -- YOUR CODE FOR TASK 2 (PART 2) --\n",
    "\n",
    "\n",
    "#Create a pandas DataFrame containing only listings in the Brooklyn neighborhood group. Don't forget to reset the index!\n",
    "df_brooklyn = ...\n",
    "\n",
    "#Printing Results\n",
    "df_brooklyn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a dataframe showing the average (mean) prices of the listings in Brooklyn\n",
    "df_brooklyn_prices_room_type = ...\n",
    "\n",
    "#Printing Results\n",
    "df_brooklyn_prices_room_type\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a pandas Series showing the number of listings for each of the top 10 most common neighbourhoods\n",
    "top_10_brooklyn_series = ...\n",
    "\n",
    "#Printing Results\n",
    "top_10_brooklyn_series\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## RUN THIS CELL AS-IS TO CHECK IF YOUR OUTPUTS ARE CORRECT. IF THEY ARE NOT,\n",
    "## THE APPROPRIATE OBJECTS WILL BE LOADED IN TO ENSURE THAT YOU CAN CONTINUE\n",
    "## WITH THE ASSESSMENT.\n",
    "\n",
    "## Checks\n",
    "task_2_part_2_top_10_check = data_load_files.TASK_2_PART_2_T10_OUTPUT\n",
    "task_2_part_2_brooklyn_check = data_load_files.TASK_2_PART_2_BKN_OUTPUT\n",
    "task_2_part_2_rm_prices_check = data_load_files.TASK_2_PART_2_RM_PRICES_OUTPUT\n",
    "\n",
    "price_shape_check = (df_brooklyn_prices_room_type.shape == task_2_part_2_rm_prices_check.shape)\n",
    "price_columns_check = (list(df_brooklyn_prices_room_type.columns) == list(task_2_part_2_rm_prices_check.columns))\n",
    "price_avg_check = (df_brooklyn_prices_room_type.price.mean() == task_2_part_2_rm_prices_check.price.mean())\n",
    "\n",
    "brooklyn_shape_check = (df_brooklyn.shape == task_2_part_2_brooklyn_check.shape)\n",
    "\n",
    "brooklyn_top_10_avg_check = (top_10_brooklyn_series.mean() == task_2_part_2_top_10_check.mean())\n",
    "\n",
    "if price_shape_check and price_columns_check and price_avg_check and brooklyn_shape_check and brooklyn_top_10_avg_check:\n",
    "    print('dfs are correct')\n",
    "else:    \n",
    "    df_brooklyn_prices_room_type = task_2_part_2_rm_prices_check\n",
    "    df_brooklyn = task_2_part_2_brooklyn_check\n",
    "    df_brooklyn['last_review'] = pd.to_datetime(df_brooklyn['last_review'])\n",
    "    top_10_brooklyn_series = task_2_part_2_top_10_check\n",
    "    print(\"df's are incorrect. You can correct for points, but you will still be able to move on to the next task if not.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3, Part 1\n",
    "\n",
    "**Instructions**\n",
    "\n",
    "We want to be able to model using the ‘neighbourhood’ column as a feature, but to do so we’ll have to transform it into a series of binary features (one per neighbourhood), and right now there are way too many unique values. To solve this problem, we will re-label all neighbourhoods not in the top 10 neighbourhoods as “Other”. First, you'll create a list of the top 10 most common neighbourhoods in Brooklyn, leveraging the `top_10_brooklyn_series` Series that you created earlier. Then you will replace all neighbourhood values NOT in that list with the value 'Other'.\n",
    "\n",
    "AirBnB believes that long lags between reviews can be an indicator that the rental unit is less desirable (not being booked often). To enable us to test this later, create a new column representing the number of days it has been since the last review was posted. \n",
    "\n",
    "AirBnB believes that ‘Entire home/apt’ rentals in Brooklyn can command a premium; hence, they would like you to separately identify such listings using a new binary column.\n",
    "\n",
    "**Expected Output**\n",
    "- (1pt) A list of neighborhoods `top_10_brooklyn_list` that contains the top 10 neighborhoods in brooklyn by largest count of Air BnBs\n",
    "- (1pt) A column `neighbourhood` that displays the neighbourhood name if it is in the `top_10_brooklyn_list`, otherwise displays \"Other\"\n",
    "- (1pt) Calculate the `days_since_review` and add as a column in `df_brooklyn`\n",
    "- (1pt) Create a binary column `brooklyn_whole` that create a binary indicator based on 'room_type'=='Entire home/apt'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Task 3\n",
    "\n",
    "# -- YOUR CODE FOR TASK 3 --\n",
    "\n",
    "#Create a list of the top 10 most common neighbourhoods, using the 'top_10_brooklyn_series'\n",
    "#that you created earlier\n",
    "top_10_brooklyn_list = ...\n",
    "\n",
    "\n",
    "#Replace all 'neighbourhood' column values NOT in the top 10 with 'Other'\n",
    "df_brooklyn['neighbourhood'] = ...\n",
    "\n",
    "# Printing Results\n",
    "df_brooklyn['neighbourhood'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Calculate the days_since_review and add as a column in df_brooklyn\n",
    "df_brooklyn['days_since_review']=...\n",
    "\n",
    "# Print Results\n",
    "df_brooklyn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create a binary column brooklyn_whole that create a binary indicator based on 'room_type'=='Entire home/apt'\n",
    "df_brooklyn['brooklyn_whole']=...\n",
    "\n",
    "# Printing Results\n",
    "df_brooklyn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## RUN THIS CELL AS-IS TO CHECK IF YOUR OUTPUTS ARE CORRECT. IF THEY ARE NOT,\n",
    "## THE APPROPRIATE OBJECTS WILL BE LOADED IN TO ENSURE THAT YOU CAN CONTINUE\n",
    "## WITH THE ASSESSMENT.\n",
    "\n",
    "task_3_part_1_check = data_load_files.TASK_3_PART_1_OUTPUT\n",
    "\n",
    "brooklyn_shape_check = (df_brooklyn.shape == task_3_part_1_check.shape)\n",
    "brooklyn_columns_check = (list(df_brooklyn.columns) == list(task_3_part_1_check.columns))\n",
    "\n",
    "if brooklyn_shape_check and brooklyn_columns_check:\n",
    "    print('df is correct')\n",
    "else:    \n",
    "    df_brooklyn = task_3_part_1_check\n",
    "    print(\"df is incorrect. You can correct for points, but you will still be able to move on to the next task if not.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3, Part 2\n",
    "\n",
    "You want to take a closer look at price in the dataset. You decide to categorize rental properties by their affordability. Categorize each listing into one of three price categories by binning the `price`  column and creating a new `price_category` column using the cut method of pandas (https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.cut.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_bins = [0, 100, 200, np.inf]\n",
    "price_cat = ['low', 'medium', 'high']\n",
    "\n",
    "#Categorize each listing into one of three price categories by binning the price column\n",
    "df_brooklyn['price_category'] = ...\n",
    "\n",
    "\n",
    "# Printing Results\n",
    "df_brooklyn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## RUN THIS CELL AS-IS TO CHECK IF YOUR OUTPUTS ARE CORRECT. IF THEY ARE NOT,\n",
    "## THE APPROPRIATE OBJECTS WILL BE LOADED IN TO ENSURE THAT YOU CAN CONTINUE\n",
    "## WITH THE ASSESSMENT.\n",
    "\n",
    "task_3_part_2_check = data_load_files.TASK_3_PART_2_OUTPUT\n",
    "\n",
    "brooklyn_shape_check = (df_brooklyn.shape == task_3_part_2_check.shape)\n",
    "brooklyn_columns_check = (list(df_brooklyn.columns) == list(task_3_part_2_check.columns))\n",
    "\n",
    "if brooklyn_shape_check and brooklyn_columns_check:\n",
    "    print('df is correct')\n",
    "else:    \n",
    "    df_brooklyn = task_3_part_2_check\n",
    "    print(\"df is incorrect. You can correct for points, but you will still be able to move on to the next task if not.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3, Part 3\n",
    "\n",
    "**Instructions**\n",
    "* Create a barchart of your dataset `Price Category` from Part 2, comparing the number of rentals in each category.\n",
    "\n",
    "\n",
    "**Expected Output**\n",
    "* barchart with listing count as bar\n",
    "* grouped by 3 price categories\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a barchart of your dataset\n",
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 4, Part 1\n",
    "\n",
    "**Instructions **\n",
    "\n",
    "Airbnb's business team would like to understand the revenue the hosts make in Brookyln. As you do not have the Airbnb booking details, you can estimate the number of bookings for each property based on the number of reviews they received. You can then extrapolate each property’s revenue with this formula:\n",
    "\n",
    "Number of Reviews x Price of Listing x Minimum Length of Stay\n",
    "\n",
    "This will serve as a conservative estimate of the revenue, since it is likely that properties will have more bookings than reviews. In addition, guests are also likely to stay longer than the minimum number of nights required.\n",
    "\n",
    "**Expected Output**\n",
    "- (1pt) Write a function called generate_estimate_host_revenue to calculate the host revenue using the above formula and return the updated dataframe `df_brooklyn` with a new column `estimated_host_revenue` using the function you created\n",
    "- (1pt) Descriptive Statistics of the `estimated_host_revenue`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a function to calculate the estimated host revenue, update the dataframe with a new column `estimated_host_revenue` calculated using the above formula\n",
    "# and return the updated dataframe\n",
    "#Your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply your function on `df_brooklyn`\n",
    "df_brooklyn = ...\n",
    "\n",
    "# Printing Results\n",
    "df_brooklyn  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use the describe() function column `estimated_host_revenue` to generate descriptive statistics which includes \n",
    "# the summary of the central tendency, dispersion and shape of the numerical column.\n",
    "\n",
    "#Your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## RUN THIS CELL AS-IS TO CHECK IF YOUR OUTPUTS ARE CORRECT. IF THEY ARE NOT,\n",
    "## THE APPROPRIATE OBJECTS WILL BE LOADED IN TO ENSURE THAT YOU CAN CONTINUE\n",
    "## WITH THE ASSESSMENT.\n",
    "\n",
    "task_4_part_1_check  = data_load_files.TASK_4_PART_1_OUTPUT \n",
    "\n",
    "brooklyn_shape_check = (df_brooklyn.shape == task_4_part_1_check.shape)\n",
    "brooklyn_columns_check = (list(df_brooklyn.columns) == list(task_4_part_1_check.columns))\n",
    "brooklyn_est_host_rev_mean_check = (df_brooklyn['estimated_host_revenue'].mean() == task_4_part_1_check['estimated_host_revenue'].mean())\n",
    "brooklyn_est_host_rev_max_check = (df_brooklyn['estimated_host_revenue'].max() == task_4_part_1_check['estimated_host_revenue'].max())\n",
    "\n",
    "if brooklyn_shape_check and brooklyn_columns_check and brooklyn_est_host_rev_mean_check and brooklyn_est_host_rev_max_check:\n",
    "    print('df is correct')\n",
    "else:    \n",
    "    df_brooklyn = task_4_part_1_check\n",
    "    print(\"df is incorrect. You can correct for points, but you will still be able to move on to the next task if not.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 4, Part 2\n",
    "\n",
    "**Instructions**\n",
    "\n",
    "The AirBnB team wants more information on average prices of different types of listings. To help them with this, use a pivot table to look at the average (mean) prices for the various room types within each 'neighbourhood'. \n",
    "\n",
    "https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.pivot_table.html#pandas.DataFrame.pivot_table\n",
    "\n",
    "\n",
    "**Expected Output**\n",
    "\n",
    " - (1pt) Correct Pivot Table with `room_type` as column and `neighbourhood` as index\n",
    " - (1pt) Fill the cell with 0 if value is null\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE FOR TASK 4, PART 2\n",
    "Pivot = ...\n",
    "\n",
    "# Printing Results\n",
    "Pivot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASK 5, Part 1\n",
    "**Instructions**\n",
    "\n",
    "The Airbnb analysts want to know the factors influencing the price. Before proceedeing with Correlation analysis, you need to perform some feature engineering tasks such as converting the categorical columns, dropping descriptive columns.\n",
    "\n",
    "1. Encode the categorical variable `room_type` and `neighbourhood` using One-Hot Encoding.\n",
    "\n",
    "Many machine learning algorithms cannot work with categorical data directly. The categories must be converted into numbers. One hot encoding creates new (binary) columns, indicating the presence of each possible value from the original data. \n",
    "\n",
    "Use pandas get_dummies function to create One-Hot Encoding.  \n",
    "\n",
    "Function syntax : new_dataframe  = pd.get_dummies(dataframe name, columns = [list of categorical columns])\n",
    "\n",
    "2. Drop the the descriptive columns `name`, `host_id`, `host_name`, `neighbourhood_group`, `latitude` and `longitude` from the dataframe. \n",
    "\n",
    "Expected Output\n",
    "\n",
    " - (2pt) Dataframe `df_brooklyn_rt` contains 19 columns now.\n",
    " - (1pt) Drop descriptive columns `name`, `host_id`, `host_name`, `neighbourhood_group`, `latitude` and `longitude`from the dataframe\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE FOR TASK 5, PART 1\n",
    "# encode the columnns room_type and neighbourhood\n",
    "df_brooklyn_rt = ...\n",
    "\n",
    "# Printing Results\n",
    "df_brooklyn_rt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop the descriptive columns from the dataframe \n",
    "df_brooklyn_rt = ...\n",
    "\n",
    "# Printing Results\n",
    "df_brooklyn_rt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## RUN THIS CELL AS-IS TO CHECK IF YOUR OUTPUTS ARE CORRECT. IF THEY ARE NOT,\n",
    "## THE APPROPRIATE OBJECTS WILL BE LOADED IN TO ENSURE THAT YOU CAN CONTINUE\n",
    "## WITH THE ASSESSMENT.\n",
    "task_5_part_1_check  = data_load_files.TASK_5_PART_1_OUTPUT \n",
    "\n",
    "brooklyn_rt_shape_check = (df_brooklyn_rt.shape == task_5_part_1_check.shape)\n",
    "brooklyn_rt_columns_check = (list(df_brooklyn_rt.columns) == list(task_5_part_1_check.columns))\n",
    "\n",
    "if brooklyn_rt_shape_check and brooklyn_rt_columns_check:\n",
    "    print('df is correct')\n",
    "else:    \n",
    "    df_brooklyn_rt = task_5_part_1_check\n",
    "    print(\"df is incorrect. You can correct for points, but you will still be able to move on to the next task if not.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 5, Part 2\n",
    "**Instructions**\n",
    "\n",
    "We will now study the correlation of the features in the dataset with `price`. Use Pandas dataframe.corr() to find the pairwise correlation of all columns in the dataframe. \n",
    "\n",
    "Use pandas corr() function to create correlation dataframe.\n",
    "\n",
    "Function syntax : new_dataframe = Dataframe.corr()\n",
    "\n",
    "Visualize the correaltion dataframe using a seaborm heatmap. Heatmap is used to plot rectangular data as a color-encoded matrix.\n",
    "https://seaborn.pydata.org/generated/seaborn.heatmap.html\n",
    "\n",
    "Expected Output\n",
    "\n",
    " - (2pt) Visualize the Correlation matrix using a heatmap\n",
    " - (1pt) Correct labels for x and y axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE FOR TASK 5, PART 2\n",
    "# create a correlation matix\n",
    "corr = ...\n",
    "\n",
    "# plot the heatmap\n",
    "sns.heatmap(...)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Think about it**: Multicollinearity occurs when your data includes multiple attributes that are correlated not just to your target variable, but also to each other. \n",
    "\n",
    "Based on the correlation matrix, **think about** the following:\n",
    "\n",
    "1. Which columns would you drop to prevent multicollinearity? \n",
    "Sample Answer: brooklyn_whole or number_of_reviews\n",
    "2. Which columns do you find are positively related to the price?\n",
    "Sample Answer: reviews_per_month\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## RUN THIS CELL AS-IS TO CHECK IF YOUR OUTPUTS ARE CORRECT. IF THEY ARE NOT,\n",
    "## THE APPROPRIATE OBJECTS WILL BE LOADED IN TO ENSURE THAT YOU CAN CONTINUE\n",
    "## WITH THE ASSESSMENT.\n",
    "task_5_part_2_check = data_load_files.TASK_5_PART_2_OUTPUT\n",
    "\n",
    "corr_shape_check = (corr.shape == task_5_part_2_check.shape)\n",
    "      \n",
    "if corr_shape_check:\n",
    "    print('df is correct')\n",
    "else:    \n",
    "    print(\"df is incorrect. You can correct for points, but you will still be able to move on to the next task if not.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 6\n",
    "\n",
    "Property Hosts are expected to set their own prices for their listings. Although Airbnb provide some general guidance, there are currently no services which help hosts price their properties using range of data points.\n",
    "\n",
    "Airbnb pricing is important to get right, particularly in big cities like New York where there is a lot of competition and even small differences in prices can make a big difference. It is also a difficult thing to do correctly — price too high and no one will book. Price too low and you’ll be missing out on a lot of potential income.\n",
    "\n",
    "Now, let’s try to make a price prediction model using the basic machine learning model from scikit learn. It is a linear regression model that we will use to predict the prices. Import the correct Library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 6, Part 1\n",
    "\n",
    "**Instructions**\n",
    "\n",
    "**Preparing the data for training the model**\n",
    "Based on the correlation plot observations,  we have now identified the features that influence the price of an accomodation. We will prepare the data to train the price prediction model. \n",
    "\n",
    "We will create two dataframes 'X' (contains all features influencing the price) and 'Y' (contains the feature price) from `df_brooklyn_rt`. \n",
    "1. To create Y, select the `price` column from `df_brooklyn_rt`\n",
    "2. To create X, drop the columns `price`, `last_review`, `brooklyn_whole`,`price_category` from `df_brooklyn_rt`. We are dropping `brooklyn_whole` as it was causing multicollinearity with `room_type`.\n",
    "\n",
    "    \n",
    "**Splitting the data into training and testing sets**\n",
    "\n",
    "Next, we split the X and Y datasets into training and testing sets. We train the model with 80% of the samples and test with the remaining 20%. We do this to assess the model’s performance on unseen data. To split the data we use train_test_split function provided by scikit-learn library. We finally print the sizes of our training and test set to verify if the splitting has occurred properly.\n",
    "\n",
    "**Note**: Please don't change the value for `random_state` in your code, it should set be 5.\n",
    "    \n",
    "**Expected Output**\n",
    "- (1pt) Create dataframe Y from `df_brooklyn_rt`, select only column `price`\n",
    "- (1pt) Create dataframe X from `df_brooklyn_rt`, do not include columns `price`, `last_review`,` brooklyn_whole` and `price_category`\n",
    "- (1pt) Split the dataframes X and Y into train and test datasets using the train_test_split function\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code here \n",
    "X = \n",
    "Y ="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code here \n",
    "#Please don't change the test_size value it should remain 0.2\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(<....your X value here...>, <your Y value here>, test_size = 0.2, random_state=5)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_train.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## RUN THIS CELL AS-IS TO CHECK IF YOUR OUTPUTS ARE CORRECT. IF THEY ARE NOT,\n",
    "## THE APPROPRIATE OBJECTS WILL BE LOADED IN TO ENSURE THAT YOU CAN CONTINUE\n",
    "## WITH THE ASSESSMENT.\n",
    "task_6_part_1_output_1_check  = data_load_files.TASK_6_PART_1_OUTPUT_1\n",
    "task_6_part_1_output_2_check  = data_load_files.TASK_6_PART_1_OUTPUT_2\n",
    "task_6_part_1_output_3_check  = data_load_files.TASK_6_PART_1_OUTPUT_3\n",
    "task_6_part_1_output_4_check  = data_load_files.TASK_6_PART_1_OUTPUT_4\n",
    "\n",
    "#X_train\n",
    "xtrain_shape_check = (X_train.shape == task_6_part_1_output_1_check.shape)\n",
    "xtrain_columns_check = (list(X_train.columns) == list(task_6_part_1_output_1_check.columns))\n",
    "\n",
    "#X_test\n",
    "xtest_shape_check = (X_test.shape == task_6_part_1_output_2_check.shape)\n",
    "xtest_columns_check = (list(X_test.columns) == list(task_6_part_1_output_2_check.columns))\n",
    "\n",
    "if xtrain_shape_check and xtrain_columns_check and \\\n",
    "   xtest_shape_check and xtest_columns_check:\n",
    "    print('dfs are correct')\n",
    "else:    \n",
    "    X_train = task_6_part_1_output_1_check\n",
    "    X_test = task_6_part_1_output_2_check\n",
    "    Y_train = task_6_part_1_output_3_check\n",
    "    Y_test = task_6_part_1_output_4_check\n",
    "    print(\"dfs are incorrect. You can correct for points, but you will still be able to move on to the next task if not.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 6, Part 2\n",
    "\n",
    "**Instructions**\n",
    "\n",
    "Training the model\n",
    "We use scikit-learn’s LinearRegression to train our model. Using the fit() method, we will pass the training datasets X_train and Y_train as arguments to the linear regression model. \n",
    "\n",
    "Testing the model\n",
    "The model has learnt about the dataset. We will now use the trained model on the test dataset, X_test. Using the predict() method, we will pass the test dataset X_Test as an argument to the model.\n",
    "\n",
    "Expected Output\n",
    "- (1pt) Pass the training datasets X_train and Y_train to the fit method as arguments\n",
    "- (1pt) Pass the test dataset X_test to the predict method as argument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run this cell\n",
    "lin_model = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training the model\n",
    "#Your code here\n",
    "lin_model.fit(..X_argument.., ..Y_argument..)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing the model\n",
    "y_test_predict = lin_model.predict(...X test Dataset...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run this cell\n",
    "#Model Evaluation\n",
    "rmse = (np.sqrt(mean_squared_error(Y_test, y_test_predict)))\n",
    "r2 = r2_score(Y_test, y_test_predict)\n",
    "\n",
    "print(\"The model performance for testing set\")\n",
    "print(\"--------------------------------------\")\n",
    "print('RMSE is {}'.format(round(rmse,3)))\n",
    "print('R2 score is {}'.format(round(r2,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## RUN THIS CELL AS-IS TO CHECK IF YOUR OUTPUTS ARE CORRECT. IF THEY ARE NOT,\n",
    "## THE APPROPRIATE OBJECTS WILL BE LOADED IN TO ENSURE THAT YOU CAN CONTINUE\n",
    "## WITH THE ASSESSMENT.\n",
    "task_6_part_2_check  = data_load_files.TASK_6_PART_2_OUTPUT\n",
    "round(rmse,3)\n",
    "rmse_check = (round(rmse,3) == task_6_part_2_check['RMSE'][0])\n",
    "r2_check = (round(r2,3) == task_6_part_2_check['R2'][0])\n",
    "if rmse_check and r2_check:\n",
    "    print('Model evaluation is correct')\n",
    "else:\n",
    "    print('Model evaluation is incorrect')\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 6, Part 3\n",
    "\n",
    "**Instructions**\n",
    "\n",
    "Now we will compare the actual output values for X_test with the predicted values using a bar chart.\n",
    "\n",
    "\n",
    "- 1(pt) Create a new dataframe <code>lr_pred_df</code> using the <code>Y_test</code> and <code>y_test_predict</code>. Hint: You'll need to flatten your arrays\n",
    "- 1(pt) Use first 20 records from the dataframe <code>lr_pred_df</code> and plot a bar graph showing comparision of actual and predicted values set Y axis label as 'Price' and Plot title as 'Actual vs Predicted Price'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Actual Vs Predicted for Linear Regression\n",
    "lr_pred_df = ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code here\n",
    "lr_pred_df = ...\n",
    "lr_pred_df.plot(...kind...) \n",
    "\n",
    "# Printing Results\n",
    "plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## RUN THIS CELL AS-IS TO CHECK IF YOUR OUTPUTS ARE CORRECT. IF THEY ARE NOT,\n",
    "## THE APPROPRIATE OBJECTS WILL BE LOADED IN TO ENSURE THAT YOU CAN CONTINUE\n",
    "## WITH THE ASSESSMENT.\n",
    "task_6_part_3_check  = data_load_files.TASK_6_PART_3_OUTPUT \n",
    "\n",
    "lr_pred_df_shape_check = (lr_pred_df.shape == task_6_part_3_check.shape)\n",
    "lr_pred_df_columns_check = (list(lr_pred_df.columns) == list(task_6_part_3_check.columns))\n",
    "\n",
    "if lr_pred_df_shape_check and lr_pred_df_columns_check:\n",
    "    print('df is correct')\n",
    "else:    \n",
    "    lr_pred_df = task_6_part_3_check\n",
    "    print(\"df is incorrect. You can correct for points, but you will still be able to move on to the next task if not.\")"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
